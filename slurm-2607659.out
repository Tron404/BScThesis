The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) 2023.01   2) StdEnv

The following have been reloaded with a version change:
  1) GCCcore/12.2.0 => GCCcore/11.3.0
  2) GMP/6.2.1-GCCcore-12.2.0 => GMP/6.2.1-GCCcore-11.3.0
  3) Python/3.10.8-GCCcore-12.2.0 => Python/3.10.4-GCCcore-11.3.0
  4) SQLite/3.39.4-GCCcore-12.2.0 => SQLite/3.38.3-GCCcore-11.3.0
  5) Tcl/8.6.12-GCCcore-12.2.0 => Tcl/8.6.12-GCCcore-11.3.0
  6) XZ/5.2.7-GCCcore-12.2.0 => XZ/5.2.5-GCCcore-11.3.0
  7) binutils/2.39-GCCcore-12.2.0 => binutils/2.38-GCCcore-11.3.0
  8) bzip2/1.0.8-GCCcore-12.2.0 => bzip2/1.0.8-GCCcore-11.3.0
  9) libffi/3.4.4-GCCcore-12.2.0 => libffi/3.4.2-GCCcore-11.3.0
 10) libreadline/8.2-GCCcore-12.2.0 => libreadline/8.1.2-GCCcore-11.3.0
 11) ncurses/6.3-GCCcore-12.2.0 => ncurses/6.3-GCCcore-11.3.0
 12) zlib/1.2.12-GCCcore-12.2.0 => zlib/1.2.12-GCCcore-11.3.0

2023-06-18 17:51:46.263872: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
True
True
--------- Using lcc
2023-06-18 17:51:54.608857: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:51:54.608862: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:51:54.655945: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:51:54.680737: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:51:54.680737: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:51:54.680742: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:51:54.680738: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:51:54.680736: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:51:54.680737: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:51:54.680738: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
True
True
fr-ro for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.0044403076171875s to process the data for fr-ro
True
True
ro-nl for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.005030632019042969s to process the data for ro-nl
True
True
ro-fr for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.0074269771575927734s to process the data for ro-fr
True
True
en-ro for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.006666660308837891s to process the data for en-ro
True
True
en-nl for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.007035732269287109s to process the data for en-nl
True
True
ro-en for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.005965709686279297s to process the data for ro-en
True
True
en-fr for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.005645275115966797s to process the data for en-fr
True
True
fr-en for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.005392551422119141s to process the data for fr-en
True
True
en-de for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.0033485889434814453s to process the data for en-de
True
True
ro-de for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.0043315887451171875s to process the data for ro-de
Reached 10 processes - joining
2023-06-18 17:52:00.778158: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:00.778164: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:00.778164: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:00.787097: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:00.790378: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:00.791179: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:00.791183: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:00.791340: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:00.792045: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:00.792464: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
True
True
nl-en for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.009396553039550781s to process the data for nl-en
True
True
nl-de for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.013354778289794922s to process the data for nl-de
True
True
nl-fr for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.011524438858032227s to process the data for nl-fr
True
True
fr-nl for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.011002063751220703s to process the data for fr-nl
True
True
de-en for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.013559818267822266s to process the data for de-en
True
True
nl-ro for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.006620645523071289s to process the data for nl-ro
True
True
de-fr for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.006714820861816406s to process the data for de-fr
True
True
de-ro for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.0042836666107177734s to process the data for de-ro
True
True
de-nl for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.007163047790527344s to process the data for de-nl
True
True
fr-de for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.005542278289794922s to process the data for fr-de
Reached 10 processes - joining
2023-06-18 17:52:05.824152: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:05.844216: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:05.847162: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:05.896976: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:05.896975: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:05.896975: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:05.896976: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:05.900777: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:05.902197: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:05.915643: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
True
True
en-ro for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.016272306442260742s to process the data for en-ro
True
True
en-nl for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.010573387145996094s to process the data for en-nl
True
True
en-de for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.016028642654418945s to process the data for en-de
True
True
ro-nl for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.009474515914916992s to process the data for ro-nl
True
True
fr-ro for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.007416486740112305s to process the data for fr-ro
True
True
en-fr for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.007984399795532227s to process the data for en-fr
True
True
ro-de for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.007854938507080078s to process the data for ro-de
True
True
fr-en for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.007050991058349609s to process the data for fr-en
True
True
ro-en for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.0056934356689453125s to process the data for ro-en
True
True
ro-fr for lcc is already present, moving to the next pair
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 0.0052776336669921875s to process the data for ro-fr
Reached 10 processes - joining
2023-06-18 17:52:11.235969: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:11.235968: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:11.235968: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:11.253574: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:11.278173: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:11.285218: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:11.295337: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:11.295335: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:11.295332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-06-18 17:52:11.295335: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
/home2/s4231317/mapping_script_MP.py:61: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /dev/shm/bob/PyTorch/1.12.1/foss-2022a-CUDA-11.7.0/pytorch-v1.12.1/torch/csrc/utils/tensor_numpy.cpp:172.)
  sl_vec = torch.as_tensor(sl_vec).to(device)
/home2/s4231317/mapping_script_MP.py:61: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /dev/shm/bob/PyTorch/1.12.1/foss-2022a-CUDA-11.7.0/pytorch-v1.12.1/torch/csrc/utils/tensor_numpy.cpp:172.)
  sl_vec = torch.as_tensor(sl_vec).to(device)
/home2/s4231317/mapping_script_MP.py:61: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /dev/shm/bob/PyTorch/1.12.1/foss-2022a-CUDA-11.7.0/pytorch-v1.12.1/torch/csrc/utils/tensor_numpy.cpp:172.)
  sl_vec = torch.as_tensor(sl_vec).to(device)
/home2/s4231317/mapping_script_MP.py:61: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /dev/shm/bob/PyTorch/1.12.1/foss-2022a-CUDA-11.7.0/pytorch-v1.12.1/torch/csrc/utils/tensor_numpy.cpp:172.)
  sl_vec = torch.as_tensor(sl_vec).to(device)
/home2/s4231317/mapping_script_MP.py:61: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /dev/shm/bob/PyTorch/1.12.1/foss-2022a-CUDA-11.7.0/pytorch-v1.12.1/torch/csrc/utils/tensor_numpy.cpp:172.)
  sl_vec = torch.as_tensor(sl_vec).to(device)
/home2/s4231317/mapping_script_MP.py:61: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /dev/shm/bob/PyTorch/1.12.1/foss-2022a-CUDA-11.7.0/pytorch-v1.12.1/torch/csrc/utils/tensor_numpy.cpp:172.)
  sl_vec = torch.as_tensor(sl_vec).to(device)
/home2/s4231317/mapping_script_MP.py:61: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /dev/shm/bob/PyTorch/1.12.1/foss-2022a-CUDA-11.7.0/pytorch-v1.12.1/torch/csrc/utils/tensor_numpy.cpp:172.)
  sl_vec = torch.as_tensor(sl_vec).to(device)
/home2/s4231317/mapping_script_MP.py:61: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /dev/shm/bob/PyTorch/1.12.1/foss-2022a-CUDA-11.7.0/pytorch-v1.12.1/torch/csrc/utils/tensor_numpy.cpp:172.)
  sl_vec = torch.as_tensor(sl_vec).to(device)
/home2/s4231317/mapping_script_MP.py:61: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /dev/shm/bob/PyTorch/1.12.1/foss-2022a-CUDA-11.7.0/pytorch-v1.12.1/torch/csrc/utils/tensor_numpy.cpp:172.)
  sl_vec = torch.as_tensor(sl_vec).to(device)
/home2/s4231317/mapping_script_MP.py:61: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /dev/shm/bob/PyTorch/1.12.1/foss-2022a-CUDA-11.7.0/pytorch-v1.12.1/torch/csrc/utils/tensor_numpy.cpp:172.)
  sl_vec = torch.as_tensor(sl_vec).to(device)
True
True
de-fr <function lcc at 0x7ff5b4ffbac0> Thesis/Results/mate_retrieval/de-fr/
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: bert-base-multilingual-uncased | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]True
True
nl-de <function lcc at 0x7fe724267ac0> Thesis/Results/mate_retrieval/nl-de/
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: bert-base-multilingual-uncased | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]True
True
nl-fr <function lcc at 0x7f582adbbac0> Thesis/Results/mate_retrieval/nl-fr/
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: bert-base-multilingual-uncased | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]True
True
fr-nl <function lcc at 0x7f1815307ac0> Thesis/Results/mate_retrieval/fr-nl/
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: bert-base-multilingual-uncased | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]True
True
de-nl <function lcc at 0x7f649790fac0> Thesis/Results/mate_retrieval/de-nl/
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: bert-base-multilingual-uncased | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]True
True
de-ro <function lcc at 0x7f0ad206bac0> Thesis/Results/mate_retrieval/de-ro/
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: bert-base-multilingual-uncased | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]True
True
fr-de <function lcc at 0x7f0fbc5b7b50> Thesis/Results/mate_retrieval/fr-de/
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: bert-base-multilingual-uncased | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]True
True
de-en <function lcc at 0x7f1fa2cffac0> Thesis/Results/mate_retrieval/de-en/
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: bert-base-multilingual-uncased | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]True
True
nl-ro <function lcc at 0x7f8ca8917ac0> Thesis/Results/mate_retrieval/nl-ro/
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: bert-base-multilingual-uncased | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]True
True
nl-en <function lcc at 0x7f6993f5fac0> Thesis/Results/mate_retrieval/nl-en/
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: bert-base-multilingual-uncased | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:   7%|▋         | 1/15 [00:36<08:30, 36.50s/it]LCC:   7%|▋         | 1/15 [00:36<08:31, 36.53s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:   7%|▋         | 1/15 [00:37<08:46, 37.59s/it]LCC:   7%|▋         | 1/15 [00:37<08:48, 37.75s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:   7%|▋         | 1/15 [00:38<08:55, 38.28s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:   7%|▋         | 1/15 [00:38<09:05, 38.99s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:   7%|▋         | 1/15 [00:39<09:07, 39.08s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:   7%|▋         | 1/15 [00:38<09:05, 38.93s/it]LCC:   7%|▋         | 1/15 [00:38<09:05, 38.99s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [01:23<09:12, 42.50s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [01:24<09:19, 43.07s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [01:24<09:21, 43.21s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [01:25<09:21, 43.18s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [01:25<09:25, 43.48s/it]LCC:  13%|█▎        | 2/15 [01:25<09:25, 43.47s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [01:29<09:57, 46.00s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [02:25<10:18, 51.57s/it]LCC:  20%|██        | 3/15 [02:26<10:16, 51.40s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [02:26<10:19, 51.65s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [02:26<10:24, 52.05s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [02:27<10:22, 51.91s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [02:30<10:42, 53.55s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [02:35<10:59, 54.99s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [03:58<12:24, 67.72s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [03:59<12:28, 68.06s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [04:00<12:31, 68.31s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [04:02<12:43, 69.40s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [04:03<12:40, 69.16s/it]LCC:  27%|██▋       | 4/15 [04:03<12:36, 68.74s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [04:08<12:49, 70.00s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [06:09<15:05, 90.56s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [06:10<15:00, 90.07s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [06:12<15:10, 91.02s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [06:13<14:56, 89.69s/it]LCC:  33%|███▎      | 5/15 [06:13<15:14, 91.44s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [06:13<15:18, 91.88s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [06:13<15:13, 91.39s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  40%|████      | 6/15 [08:51<17:11, 114.58s/it]LCC:  40%|████      | 6/15 [08:51<17:05, 113.96s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  40%|████      | 6/15 [08:53<17:13, 114.88s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  40%|████      | 6/15 [08:54<17:14, 114.91s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  40%|████      | 6/15 [08:56<17:11, 114.57s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  40%|████      | 6/15 [08:56<17:23, 115.94s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  40%|████      | 6/15 [08:57<17:24, 116.07s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  47%|████▋     | 7/15 [11:54<18:09, 136.14s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  47%|████▋     | 7/15 [11:57<18:23, 137.98s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  47%|████▋     | 7/15 [11:58<18:19, 137.38s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  47%|████▋     | 7/15 [12:00<18:29, 138.74s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  47%|████▋     | 7/15 [12:03<18:26, 138.30s/it]LCC:  47%|████▋     | 7/15 [12:03<18:35, 139.47s/it]LCC:  47%|████▋     | 7/15 [12:03<18:33, 139.18s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [15:24<18:40, 160.02s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [15:30<18:51, 161.67s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [15:30<18:47, 161.07s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [15:30<18:48, 161.21s/it]LCC:  53%|█████▎    | 8/15 [15:30<18:49, 161.35s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [15:34<18:51, 161.69s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [18:51<17:27, 174.62s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [18:55<17:28, 174.78s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [18:56<17:32, 175.36s/it]LCC:  60%|██████    | 9/15 [18:57<17:33, 175.66s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [18:59<17:37, 176.26s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [19:00<17:32, 175.42s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [22:54<16:18, 195.72s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [22:56<16:14, 194.85s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [22:56<16:17, 195.44s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [22:59<16:21, 196.26s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [23:04<16:28, 197.71s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [23:07<16:27, 197.44s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [27:34<14:41, 220.33s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [27:37<14:50, 222.56s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [27:39<14:48, 222.06s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [27:43<14:46, 221.59s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [27:45<14:54, 223.54s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [27:49<14:57, 224.49s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [32:46<12:24, 248.03s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [32:48<12:26, 248.85s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [32:49<12:29, 249.85s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [32:52<12:26, 248.85s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [32:53<12:25, 248.51s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [32:57<12:29, 249.92s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [38:22<09:09, 274.93s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [38:29<09:13, 276.86s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [38:32<09:15, 277.60s/it]LCC:  87%|████████▋ | 13/15 [38:32<09:13, 276.60s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [38:34<09:12, 276.45s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [38:37<09:14, 277.22s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [44:00<04:53, 293.82s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [44:09<04:55, 295.89s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [44:14<04:57, 297.08s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [44:14<04:55, 295.77s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [44:21<04:58, 298.47s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [44:27<04:59, 299.19s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [49:50<00:00, 310.76s/it]LCC: 100%|██████████| 15/15 [49:50<00:00, 199.34s/it]
[0.9567999839782715, 0.014599999412894249] [768, 100]
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: mt5-base | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [49:56<00:00, 311.31s/it]LCC: 100%|██████████| 15/15 [49:56<00:00, 199.79s/it]
[0.990399956703186, 0.13859999179840088] [600, 768]
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: mt5-base | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:   7%|▋         | 1/15 [00:10<02:22, 10.17s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [50:06<00:00, 312.47s/it]LCC: 100%|██████████| 15/15 [50:06<00:00, 200.40s/it]
[0.9807999730110168, 0.121799997985363] [500, 400]
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: mt5-base | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:   7%|▋         | 1/15 [00:14<03:16, 14.01s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [50:13<00:00, 315.67s/it]LCC: 100%|██████████| 15/15 [50:13<00:00, 200.88s/it]
[0.9583999514579773, 0.012999999336898327] [750, 150]
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: mt5-base | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [50:14<00:00, 314.82s/it]LCC: 100%|██████████| 15/15 [50:14<00:00, 200.95s/it]
[0.9879999756813049, 0.186599999666214] [768, 650]
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: mt5-base | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [50:16<00:00, 314.01s/it]LCC: 100%|██████████| 15/15 [50:16<00:00, 201.08s/it]
[0.9271999597549438, 0.008200000040233135] [768, 700]
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: mt5-base | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:   7%|▋         | 1/15 [00:14<03:27, 14.84s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:   7%|▋         | 1/15 [00:15<03:33, 15.23s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [00:40<04:49, 22.28s/it]LCC:   7%|▋         | 1/15 [00:16<03:55, 16.82s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:   7%|▋         | 1/15 [00:17<04:06, 17.63s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [00:49<05:47, 26.76s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [00:47<05:28, 25.28s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [00:47<05:29, 25.35s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [00:51<05:59, 27.62s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [00:50<05:47, 26.74s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [01:30<06:57, 34.75s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [01:35<07:05, 35.50s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [01:37<07:20, 36.67s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [01:35<07:07, 35.62s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [01:35<07:01, 35.09s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [01:41<07:29, 37.46s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [02:36<08:37, 47.05s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [02:44<08:55, 48.71s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [02:47<09:08, 49.91s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [02:43<08:54, 48.56s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [02:48<09:00, 49.12s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [02:46<09:00, 49.16s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [03:59<10:01, 60.17s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [04:19<10:52, 65.30s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [04:18<10:45, 64.59s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [04:21<11:02, 66.28s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [04:19<10:48, 64.88s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [04:22<10:55, 65.52s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  40%|████      | 6/15 [05:57<11:57, 79.71s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  40%|████      | 6/15 [06:19<12:34, 83.88s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  40%|████      | 6/15 [06:17<12:28, 83.16s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  40%|████      | 6/15 [06:17<12:18, 82.10s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  40%|████      | 6/15 [06:15<12:21, 82.43s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  40%|████      | 6/15 [06:21<12:39, 84.44s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  47%|████▋     | 7/15 [08:11<13:00, 97.51s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  47%|████▋     | 7/15 [08:35<13:28, 101.10s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  47%|████▋     | 7/15 [08:32<13:21, 100.17s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  47%|████▋     | 7/15 [08:27<13:07, 98.42s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  47%|████▋     | 7/15 [08:31<13:15, 99.40s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  47%|████▋     | 7/15 [08:33<13:19, 99.99s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [10:51<13:41, 117.33s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [11:17<14:03, 120.51s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [11:08<13:49, 118.48s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [11:14<13:54, 119.28s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [11:24<14:20, 122.94s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [11:20<14:09, 121.42s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [14:00<13:58, 139.81s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [14:23<14:05, 140.87s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [14:25<14:05, 140.97s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [14:19<14:07, 141.26s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [14:22<14:05, 140.91s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [14:28<14:13, 142.27s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [17:27<13:22, 160.41s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [18:01<13:43, 164.62s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [18:04<13:45, 165.06s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [18:00<13:49, 165.89s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [18:05<13:46, 165.38s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [18:04<13:49, 165.84s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [21:23<12:14, 183.61s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [22:24<12:59, 194.82s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [22:13<12:49, 192.40s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [22:23<12:56, 194.01s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [22:19<12:50, 192.67s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [22:20<12:53, 193.32s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [25:56<10:32, 210.87s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [27:09<11:06, 222.13s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [26:55<10:59, 219.83s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [27:10<11:06, 222.30s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [27:05<11:02, 220.88s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [27:07<11:05, 221.89s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [30:49<07:51, 235.85s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [32:07<08:15, 247.51s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [32:27<08:22, 251.33s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [32:23<08:19, 249.58s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [32:20<08:19, 249.57s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [32:23<08:20, 250.49s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [36:07<04:20, 260.57s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [37:55<04:34, 274.35s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [37:48<04:32, 272.31s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [37:40<04:33, 273.43s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [37:46<04:32, 272.52s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [37:53<04:34, 274.46s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [41:25<00:00, 277.78s/it]LCC: 100%|██████████| 15/15 [41:25<00:00, 165.69s/it]
[0.9023999571800232, 0.1727999895811081] [700, 650]
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: xlm-roberta-base | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:   7%|▋         | 1/15 [00:16<03:45, 16.08s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [00:46<05:20, 24.65s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [01:33<06:58, 34.84s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [43:19<00:00, 290.08s/it]LCC: 100%|██████████| 15/15 [43:19<00:00, 173.28s/it]
[0.9399999976158142, 0.30979999899864197] [550, 750]
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: xlm-roberta-base | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [43:32<00:00, 293.30s/it]LCC: 100%|██████████| 15/15 [43:32<00:00, 174.16s/it]
[0.9264000058174133, 0.33399999141693115] [768, 768]
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: xlm-roberta-base | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [43:14<00:00, 291.58s/it]LCC: 100%|██████████| 15/15 [43:14<00:00, 172.94s/it]
[0.8967999815940857, 0.14919999241828918] [768, 768]
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: xlm-roberta-base | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [43:25<00:00, 292.51s/it]LCC: 100%|██████████| 15/15 [43:25<00:00, 173.68s/it]
[0.9335999488830566, 0.25200000405311584] [768, 250]
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: xlm-roberta-base | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:   7%|▋         | 1/15 [00:13<03:09, 13.55s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [02:24<07:31, 41.08s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:   7%|▋         | 1/15 [00:13<03:06, 13.31s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:   7%|▋         | 1/15 [00:15<03:38, 15.63s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:   7%|▋         | 1/15 [00:20<04:43, 20.28s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [43:45<00:00, 297.76s/it]LCC: 100%|██████████| 15/15 [43:45<00:00, 175.02s/it]
[0.9335999488830566, 0.4253999888896942] [768, 750]
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: xlm-roberta-base | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [00:45<05:15, 24.25s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [00:46<05:22, 24.80s/it]LCC:   7%|▋         | 1/15 [00:17<04:02, 17.30s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [00:51<05:58, 27.55s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [00:53<06:05, 28.12s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [00:49<05:40, 26.19s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [01:32<06:55, 34.62s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [01:32<06:56, 34.72s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [01:38<07:16, 36.39s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [01:42<07:27, 37.28s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [04:09<10:41, 64.15s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [01:35<06:59, 35.00s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [02:42<08:56, 48.80s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [02:37<08:34, 46.80s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [02:44<08:51, 48.30s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [02:51<09:07, 49.80s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [02:46<09:01, 49.19s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  40%|████      | 6/15 [06:04<12:14, 81.61s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [04:13<10:38, 63.83s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [04:09<10:29, 62.92s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [04:16<10:37, 63.72s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [04:18<10:34, 63.48s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [04:25<11:13, 67.33s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  40%|████      | 6/15 [06:09<12:06, 80.76s/it]LCC:  40%|████      | 6/15 [06:13<12:27, 83.08s/it]LCC:  40%|████      | 6/15 [06:08<12:18, 82.06s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  40%|████      | 6/15 [06:06<11:45, 78.39s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  47%|████▋     | 7/15 [08:31<13:41, 102.72s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  40%|████      | 6/15 [06:27<12:52, 85.87s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  47%|████▋     | 7/15 [08:31<13:24, 100.61s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  47%|████▋     | 7/15 [08:22<13:00, 97.51s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  47%|████▋     | 7/15 [08:31<13:36, 102.02s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  47%|████▋     | 7/15 [08:38<13:46, 103.26s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  47%|████▋     | 7/15 [08:34<13:14, 99.34s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [11:21<14:29, 124.19s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [11:13<14:07, 121.13s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [11:22<14:17, 122.52s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [11:19<14:14, 122.00s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [11:11<14:00, 120.04s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [11:07<13:34, 116.39s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [14:30<14:27, 144.65s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [14:20<14:09, 141.59s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [14:30<14:18, 143.16s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [14:29<14:19, 143.25s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [14:20<14:09, 141.64s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [14:15<13:52, 138.83s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [18:01<13:44, 164.89s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [17:57<13:44, 164.81s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [17:56<13:42, 164.48s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [18:11<13:56, 167.24s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [18:13<14:01, 168.23s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [17:55<13:38, 163.71s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [21:57<12:26, 186.71s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [22:13<12:50, 192.73s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [22:23<12:52, 193.02s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [22:11<12:49, 192.31s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [22:27<12:58, 194.52s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [22:07<12:44, 191.01s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [26:15<10:25, 208.40s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [26:52<10:58, 219.45s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [27:07<11:01, 220.54s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [27:07<11:10, 223.48s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [27:12<11:06, 222.22s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [26:50<10:56, 218.80s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [31:04<07:45, 232.96s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [32:14<08:20, 250.42s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [32:24<08:19, 249.66s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [32:24<08:24, 252.07s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [31:58<08:11, 245.90s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [32:35<08:25, 252.70s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [36:08<04:14, 254.28s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [37:38<04:32, 272.49s/it]LCC:  93%|█████████▎| 14/15 [37:47<04:31, 271.90s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [37:54<04:32, 272.68s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [37:51<04:34, 274.59s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [37:27<04:30, 270.92s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [41:22<00:00, 272.28s/it]LCC: 100%|██████████| 15/15 [41:22<00:00, 165.49s/it]
[0.9175999760627747, 0.01119999960064888] [768, 100]
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: ernie-m-base_pytorch | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:   7%|▋         | 1/15 [00:20<04:43, 20.27s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [00:41<04:34, 21.12s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [01:02<04:09, 20.81s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [01:44<05:19, 29.02s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [03:25<09:12, 55.26s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [43:25<00:00, 291.77s/it]LCC: 100%|██████████| 15/15 [43:25<00:00, 173.68s/it]
[0.9703999757766724, 0.021399999037384987] [700, 500]
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: ernie-m-base_pytorch | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [43:02<00:00, 290.24s/it]LCC: 100%|██████████| 15/15 [43:02<00:00, 172.16s/it]
[0.9679999947547913, 0.017799999564886093] [700, 250]
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: ernie-m-base_pytorch | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [43:37<00:00, 294.05s/it]LCC: 100%|██████████| 15/15 [43:37<00:00, 174.51s/it]
[0.974399983882904, 0.039799999445676804] [700, 650]
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: ernie-m-base_pytorch | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [43:26<00:00, 295.23s/it]LCC: 100%|██████████| 15/15 [43:26<00:00, 173.74s/it]
[0.9391999840736389, 0.054999999701976776] [768, 600]
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: ernie-m-base_pytorch | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:   7%|▋         | 1/15 [00:11<02:45, 11.79s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [43:35<00:00, 295.63s/it]LCC: 100%|██████████| 15/15 [43:35<00:00, 174.40s/it]
[0.8759999871253967, 0.004999999888241291] [768, 100]
SL data shape: torch.Size([6487, 768]) | TL data shape: torch.Size([6487, 768])
Model: ernie-m-base_pytorch | Training data shape: torch.Size([3750, 768]) | Testing data shape: torch.Size([1250, 768])
LCC:   0%|          | 0/15 [00:00<?, ?it/s]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:   7%|▋         | 1/15 [00:14<03:25, 14.69s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:   7%|▋         | 1/15 [00:17<04:05, 17.51s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:   7%|▋         | 1/15 [00:16<03:49, 16.41s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:   7%|▋         | 1/15 [00:18<04:20, 18.64s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [00:44<05:12, 24.02s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  40%|████      | 6/15 [05:08<10:43, 71.50s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [00:49<05:45, 26.55s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [00:51<05:52, 27.10s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [00:51<05:50, 26.97s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  13%|█▎        | 2/15 [00:52<06:02, 27.86s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [01:33<07:03, 35.27s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [01:38<07:23, 36.95s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [01:39<07:21, 36.79s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [01:41<07:28, 37.41s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  20%|██        | 3/15 [01:40<07:27, 37.32s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [02:31<08:07, 44.36s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [02:45<08:53, 48.52s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [02:43<08:40, 47.32s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [02:49<09:08, 49.88s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  27%|██▋       | 4/15 [02:49<09:06, 49.71s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  47%|████▋     | 7/15 [07:34<12:46, 95.86s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [04:02<10:12, 61.27s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [04:11<10:13, 61.36s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [04:13<10:29, 62.97s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [04:14<10:30, 63.08s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  33%|███▎      | 5/15 [04:15<10:28, 62.81s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  40%|████      | 6/15 [05:51<11:36, 77.36s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [10:10<13:23, 114.79s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  40%|████      | 6/15 [06:03<11:46, 78.53s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  40%|████      | 6/15 [06:09<12:08, 80.90s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  40%|████      | 6/15 [06:08<12:01, 80.13s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  40%|████      | 6/15 [06:09<12:01, 80.18s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  47%|████▋     | 7/15 [08:13<13:09, 98.69s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  47%|████▋     | 7/15 [08:19<12:58, 97.32s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  47%|████▋     | 7/15 [08:26<13:15, 99.38s/it]LCC:  47%|████▋     | 7/15 [08:24<13:07, 98.41s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  47%|████▋     | 7/15 [08:23<13:00, 97.61s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [13:14<13:39, 136.53s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [11:03<14:09, 121.31s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [11:08<14:00, 120.14s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [11:10<13:59, 119.95s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [11:07<13:51, 118.85s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  53%|█████▎    | 8/15 [11:10<13:59, 119.95s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [16:52<13:27, 161.53s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [14:16<14:21, 143.61s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [14:13<14:02, 140.38s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [14:11<13:56, 139.42s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [14:18<14:06, 141.06s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  60%|██████    | 9/15 [14:19<14:09, 141.61s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [20:39<12:06, 181.59s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [18:11<14:19, 171.89s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [18:03<13:59, 167.94s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [18:08<14:03, 168.62s/it]LCC:  67%|██████▋   | 10/15 [18:07<14:06, 169.38s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  67%|██████▋   | 10/15 [18:12<14:09, 169.90s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [25:26<10:41, 213.87s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [22:39<13:25, 201.37s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [22:28<13:10, 197.62s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [22:33<13:15, 198.95s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  73%|███████▎  | 11/15 [22:33<13:11, 197.80s/it]LCC:  73%|███████▎  | 11/15 [22:36<13:16, 199.01s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [30:32<08:03, 241.66s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [27:27<11:22, 227.58s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [27:20<11:14, 224.82s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [27:20<11:18, 226.29s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [27:25<11:21, 227.29s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  80%|████████  | 12/15 [27:28<11:21, 227.23s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [36:07<04:29, 269.81s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [32:20<08:15, 247.66s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [32:31<08:21, 250.84s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [32:27<08:21, 250.60s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [32:33<08:21, 250.82s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  87%|████████▋ | 13/15 [32:35<08:24, 252.46s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [41:29<00:00, 285.61s/it]LCC: 100%|██████████| 15/15 [41:29<00:00, 165.96s/it]
[0.9311999678611755, 0.02579999901354313] [700, 500]
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |  491520 KB |  491520 KB |  491520 KB |
|       from large pool |       0 B  |  485376 KB |  485376 KB |  485376 KB |
|       from small pool |       0 B  |    6144 KB |    6144 KB |    6144 KB |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |  266461 KB |   20297 MB |   20297 MB |
|       from large pool |       0 B  |  264416 KB |   18564 MB |   18564 MB |
|       from small pool |       0 B  |    4095 KB |    1733 MB |    1733 MB |
|---------------------------------------------------------------------------|
| Allocations           |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |      15    |      15    |      15    |
|       from large pool |       0    |      12    |      12    |      12    |
|       from small pool |       0    |       3    |       3    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |      17    |  564271    |  564271    |
|       from large pool |       0    |      14    |     699    |     699    |
|       from small pool |       0    |       5    |  563572    |  563572    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |  491520 KB |  491520 KB |  491520 KB |
|       from large pool |       0 B  |  485376 KB |  485376 KB |  485376 KB |
|       from small pool |       0 B  |    6144 KB |    6144 KB |    6144 KB |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |  266461 KB |   20297 MB |   20297 MB |
|       from large pool |       0 B  |  264416 KB |   18564 MB |   18564 MB |
|       from small pool |       0 B  |    4095 KB |    1733 MB |    1733 MB |
|---------------------------------------------------------------------------|
| Allocations           |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |      15    |      15    |      15    |
|       from large pool |       0    |      12    |      12    |      12    |
|       from small pool |       0    |       3    |       3    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |      17    |  564271    |  564271    |
|       from large pool |       0    |      14    |     699    |     699    |
|       from small pool |       0    |       5    |  563572    |  563572    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 10450.956087112427s to process the data for de-ro
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [37:45<04:29, 269.81s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [37:37<04:28, 268.70s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [37:38<04:29, 269.08s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [37:45<04:29, 269.27s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC:  93%|█████████▎| 14/15 [37:44<04:29, 269.55s/it]/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [42:28<00:00, 275.21s/it]LCC: 100%|██████████| 15/15 [42:28<00:00, 169.88s/it]
[0.9639999866485596, 0.4262000024318695] [600, 700]
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |  491520 KB |  491520 KB |  491520 KB |
|       from large pool |       0 B  |  485376 KB |  485376 KB |  485376 KB |
|       from small pool |       0 B  |    6144 KB |    6144 KB |    6144 KB |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |  266461 KB |   20297 MB |   20297 MB |
|       from large pool |       0 B  |  264416 KB |   18564 MB |   18564 MB |
|       from small pool |       0 B  |    4095 KB |    1733 MB |    1733 MB |
|---------------------------------------------------------------------------|
| Allocations           |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |      15    |      15    |      15    |
|       from large pool |       0    |      12    |      12    |      12    |
|       from small pool |       0    |       3    |       3    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |      17    |  564271    |  564271    |
|       from large pool |       0    |      14    |     699    |     699    |
|       from small pool |       0    |       5    |  563572    |  563572    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |  491520 KB |  491520 KB |  491520 KB |
|       from large pool |       0 B  |  485376 KB |  485376 KB |  485376 KB |
|       from small pool |       0 B  |    6144 KB |    6144 KB |    6144 KB |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |  266461 KB |   20297 MB |   20297 MB |
|       from large pool |       0 B  |  264416 KB |   18564 MB |   18564 MB |
|       from small pool |       0 B  |    4095 KB |    1733 MB |    1733 MB |
|---------------------------------------------------------------------------|
| Allocations           |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |      15    |      15    |      15    |
|       from large pool |       0    |      12    |      12    |      12    |
|       from small pool |       0    |       3    |       3    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |      17    |  564271    |  564271    |
|       from large pool |       0    |      14    |     699    |     699    |
|       from small pool |       0    |       5    |  563572    |  563572    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 10776.680861234665s to process the data for nl-en
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [42:40<00:00, 277.56s/it]LCC: 100%|██████████| 15/15 [42:40<00:00, 170.71s/it]
[0.9871999621391296, 0.2651999890804291] [450, 500]
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |  491520 KB |  491520 KB |  491520 KB |
|       from large pool |       0 B  |  485376 KB |  485376 KB |  485376 KB |
|       from small pool |       0 B  |    6144 KB |    6144 KB |    6144 KB |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |  266461 KB |   20297 MB |   20297 MB |
|       from large pool |       0 B  |  264416 KB |   18564 MB |   18564 MB |
|       from small pool |       0 B  |    4095 KB |    1733 MB |    1733 MB |
|---------------------------------------------------------------------------|
| Allocations           |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |      15    |      15    |      15    |
|       from large pool |       0    |      12    |      12    |      12    |
|       from small pool |       0    |       3    |       3    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |      17    |  564271    |  564271    |
|       from large pool |       0    |      14    |     699    |     699    |
|       from small pool |       0    |       5    |  563572    |  563572    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |  491520 KB |  491520 KB |  491520 KB |
|       from large pool |       0 B  |  485376 KB |  485376 KB |  485376 KB |
|       from small pool |       0 B  |    6144 KB |    6144 KB |    6144 KB |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |  266461 KB |   20297 MB |   20297 MB |
|       from large pool |       0 B  |  264416 KB |   18564 MB |   18564 MB |
|       from small pool |       0 B  |    4095 KB |    1733 MB |    1733 MB |
|---------------------------------------------------------------------------|
| Allocations           |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |      15    |      15    |      15    |
|       from large pool |       0    |      12    |      12    |      12    |
|       from small pool |       0    |       3    |       3    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |      17    |  564271    |  564271    |
|       from large pool |       0    |      14    |     699    |     699    |
|       from small pool |       0    |       5    |  563572    |  563572    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 10779.596890211105s to process the data for de-fr
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [42:30<00:00, 275.79s/it]LCC: 100%|██████████| 15/15 [42:30<00:00, 170.02s/it]
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [42:34<00:00, 275.46s/it]LCC: 100%|██████████| 15/15 [42:34<00:00, 170.27s/it]
/home2/s4231317/mapping_methods.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  l1_vecs, l2_vecs = torch.tensor(l1_vecs).to(device), torch.tensor(l2_vecs).to(device)
LCC: 100%|██████████| 15/15 [42:35<00:00, 275.64s/it]LCC: 100%|██████████| 15/15 [42:35<00:00, 170.38s/it]
[0.9055999517440796, 0.026200000196695328] [768, 450]
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |  491520 KB |  491520 KB |  491520 KB |
|       from large pool |       0 B  |  485376 KB |  485376 KB |  485376 KB |
|       from small pool |       0 B  |    6144 KB |    6144 KB |    6144 KB |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |  266461 KB |   20297 MB |   20297 MB |
|       from large pool |       0 B  |  264416 KB |   18564 MB |   18564 MB |
|       from small pool |       0 B  |    4095 KB |    1733 MB |    1733 MB |
|---------------------------------------------------------------------------|
| Allocations           |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |      15    |      15    |      15    |
|       from large pool |       0    |      12    |      12    |      12    |
|       from small pool |       0    |       3    |       3    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |      17    |  564271    |  564271    |
|       from large pool |       0    |      14    |     699    |     699    |
|       from small pool |       0    |       5    |  563572    |  563572    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |  491520 KB |  491520 KB |  491520 KB |
|       from large pool |       0 B  |  485376 KB |  485376 KB |  485376 KB |
|       from small pool |       0 B  |    6144 KB |    6144 KB |    6144 KB |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |  266461 KB |   20297 MB |   20297 MB |
|       from large pool |       0 B  |  264416 KB |   18564 MB |   18564 MB |
|       from small pool |       0 B  |    4095 KB |    1733 MB |    1733 MB |
|---------------------------------------------------------------------------|
| Allocations           |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |      15    |      15    |      15    |
|       from large pool |       0    |      12    |      12    |      12    |
|       from small pool |       0    |       3    |       3    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |      17    |  564271    |  564271    |
|       from large pool |       0    |      14    |     699    |     699    |
|       from small pool |       0    |       5    |  563572    |  563572    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 10780.815467596054s to process the data for nl-ro
[0.9839999675750732, 0.4851999878883362] [400, 650]
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |  491520 KB |  491520 KB |  491520 KB |
|       from large pool |       0 B  |  485376 KB |  485376 KB |  485376 KB |
|       from small pool |       0 B  |    6144 KB |    6144 KB |    6144 KB |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |  266461 KB |   20297 MB |   20297 MB |
|       from large pool |       0 B  |  264416 KB |   18564 MB |   18564 MB |
|       from small pool |       0 B  |    4095 KB |    1733 MB |    1733 MB |
|---------------------------------------------------------------------------|
| Allocations           |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |      15    |      15    |      15    |
|       from large pool |       0    |      12    |      12    |      12    |
|       from small pool |       0    |       3    |       3    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |      17    |  564271    |  564271    |
|       from large pool |       0    |      14    |     699    |     699    |
|       from small pool |       0    |       5    |  563572    |  563572    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |  491520 KB |  491520 KB |  491520 KB |
|       from large pool |       0 B  |  485376 KB |  485376 KB |  485376 KB |
|       from small pool |       0 B  |    6144 KB |    6144 KB |    6144 KB |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |  266461 KB |   20297 MB |   20297 MB |
|       from large pool |       0 B  |  264416 KB |   18564 MB |   18564 MB |
|       from small pool |       0 B  |    4095 KB |    1733 MB |    1733 MB |
|---------------------------------------------------------------------------|
| Allocations           |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |      15    |      15    |      15    |
|       from large pool |       0    |      12    |      12    |      12    |
|       from small pool |       0    |       3    |       3    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |      17    |  564271    |  564271    |
|       from large pool |       0    |      14    |     699    |     699    |
|       from small pool |       0    |       5    |  563572    |  563572    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 10781.300697803497s to process the data for de-en
[0.9847999811172485, 0.44119998812675476] [750, 768]
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |  491520 KB |  491520 KB |  491520 KB |
|       from large pool |       0 B  |  485376 KB |  485376 KB |  485376 KB |
|       from small pool |       0 B  |    6144 KB |    6144 KB |    6144 KB |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |  266461 KB |   20297 MB |   20297 MB |
|       from large pool |       0 B  |  264416 KB |   18564 MB |   18564 MB |
|       from small pool |       0 B  |    4095 KB |    1733 MB |    1733 MB |
|---------------------------------------------------------------------------|
| Allocations           |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |      15    |      15    |      15    |
|       from large pool |       0    |      12    |      12    |      12    |
|       from small pool |       0    |       3    |       3    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |      17    |  564271    |  564271    |
|       from large pool |       0    |      14    |     699    |     699    |
|       from small pool |       0    |       5    |  563572    |  563572    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |  314710 KB |   22312 MB |   22312 MB |
|       from large pool |       0 B  |  314710 KB |   21709 MB |   21709 MB |
|       from small pool |       0 B  |    5432 KB |     602 MB |     602 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |  491520 KB |  491520 KB |  491520 KB |
|       from large pool |       0 B  |  485376 KB |  485376 KB |  485376 KB |
|       from small pool |       0 B  |    6144 KB |    6144 KB |    6144 KB |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |  266461 KB |   20297 MB |   20297 MB |
|       from large pool |       0 B  |  264416 KB |   18564 MB |   18564 MB |
|       from small pool |       0 B  |    4095 KB |    1733 MB |    1733 MB |
|---------------------------------------------------------------------------|
| Allocations           |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |    5019    |    1127 K  |    1127 K  |
|       from large pool |       0    |      18    |       1 K  |       1 K  |
|       from small pool |       0    |    5005    |    1126 K  |    1126 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |      15    |      15    |      15    |
|       from large pool |       0    |      12    |      12    |      12    |
|       from small pool |       0    |       3    |       3    |       3    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |      17    |  564271    |  564271    |
|       from large pool |       0    |      14    |     699    |     699    |
|       from small pool |       0    |       5    |  563572    |  563572    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

It took 10781.652414560318s to process the data for fr-de
Reached 10 processes - joining
/cvmfs/hpc.rug.nl/versions/2023.01/rocky8/x86_64/amd/zen3/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 4 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
slurmstepd: error: Detected 4 oom-kill event(s) in StepId=2607659.batch. Some of your processes may have been killed by the cgroup out-of-memory handler.

###############################################################################
Hábrók Cluster
Job 2607659 for user 's4231317'
Finished at: Sun Jun 18 20:51:58 CEST 2023

Job details:
============

Job ID              : 2607659
Name                : map
User                : s4231317
Partition           : gpushort
Nodes               : a100gpu6
Number of Nodes     : 1
Cores               : 10
Number of Tasks     : 1
State               : OUT_OF_MEMORY
Submit              : 2023-06-18T12:22:01
Start               : 2023-06-18T17:51:37
End                 : 2023-06-18T20:51:58
Reserved walltime   :   04:00:00
Used walltime       :   03:00:21
Used CPU time       : 1-03:59:57 (efficiency: 93.15%)
% User (Computation): 70.05%
% System (I/O)      : 29.95%
Mem reserved        : 20G
Max Mem (Node/step) : 19.42G (a100gpu6, per node)
Full Max Mem usage  : 19.42G
Total Disk Read     : 7.88M
Total Disk Write    : 967.00K

Acknowledgements:
=================

Please see this page for information about acknowledging Hábrók in your publications:

https://wiki.hpc.rug.nl/habrok/introduction/scientific_output

################################################################################
