{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "d5zhvEi5twQP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLDR.ipynb\t\t  embeddings.py        slurm-1085587.out  Thesis\r\n",
      "config_cpu.sh\t\t  nltk_data\t       slurm-1090340.out  virtual_env\r\n",
      "config_gpu.sh\t\t  Preprocessing.ipynb  slurm-1104361.out\r\n",
      "doc2vec_embeddings.ipynb  __pycache__\t       start_env.sh\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M9VXDnv_uHjG",
    "outputId": "9d4b5002-b09f-4a85-9d61-3e018be606b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home2/s4231317/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home2/s4231317/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home2/s4231317/Thesis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')    \n",
    "\n",
    "if \"thesis_code\" not in os.listdir(\"Thesis\"):\n",
    "    !git clone https://github.com/marc-lenz/thesis_code.git\n",
    "\n",
    "%cd Thesis\n",
    "from thesis_code.Preprocessor import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sgSLKSkLtzOu"
   },
   "outputs": [],
   "source": [
    "languages = [\"en\", \"ro\", \"es\", \"fr\", \"de\", \"nl\"]\n",
    "\n",
    "df = pd.read_csv(\"Data/data_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 746
    },
    "id": "HBKgkLj9gRHp",
    "outputId": "ea437615-9d4d-42cc-da18-0e6f2a75bbfc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>body_en</th>\n",
       "      <th>body_ro</th>\n",
       "      <th>body_es</th>\n",
       "      <th>body_fr</th>\n",
       "      <th>body_de</th>\n",
       "      <th>body_nl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31969R2264</td>\n",
       "      <td>Regulation (EEC) No 2264/69 of the Commissio...</td>\n",
       "      <td>REGULAMENTUL COMISIEI (CEE) nr. 2264/69 din...</td>\n",
       "      <td>Reglamento (CEE) nº 2264/69 de la Comisión, ...</td>\n",
       "      <td>Règlement (CEE) n° 2264/69 de la Commission,...</td>\n",
       "      <td>Verordnung (EWG) Nr. 2264/69 der Kommission ...</td>\n",
       "      <td>Verordening (EEG) nr. 2264/69 van de Commiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31969L0466</td>\n",
       "      <td>Council Directive 69/466/EEC of 8 December 1...</td>\n",
       "      <td>DIRECTIVA 69/466/CEE A CONSILIULUI din 8 de...</td>\n",
       "      <td>Directiva 69/466/CEE del Consejo, de 8 de di...</td>\n",
       "      <td>Directive 69/466/CEE du Conseil, du 8 décemb...</td>\n",
       "      <td>Richtlinie 69/466/EWG des Rates vom 8. Dezem...</td>\n",
       "      <td>Richtlijn 69/466/EEG van de Raad van 8 decem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31969R2602</td>\n",
       "      <td>Regulation (EEC) No 2602/69 of the Council o...</td>\n",
       "      <td>REGULAMENTUL (CEE) nr. 2602/69 AL CONSILIUL...</td>\n",
       "      <td>Reglamento (CEE) nº 2602/69 del Consejo, de ...</td>\n",
       "      <td>Règlement (CEE) n° 2602/69 du Conseil, du 18...</td>\n",
       "      <td>Verordnung (EWG) Nr. 2602/69 des Rates vom 1...</td>\n",
       "      <td>Verordening (EEG) nr. 2602/69 van de Raad va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31969L0464</td>\n",
       "      <td>Council Directive 69/464/EEC of 8 December 1...</td>\n",
       "      <td>DIRECTIVA 69/464/CEE A CONSILIULUI din 8 de...</td>\n",
       "      <td>Directiva 69/464/CEE del Consejo, de 8 de di...</td>\n",
       "      <td>Directive 69/464/CEE du Conseil, du 8 décemb...</td>\n",
       "      <td>Richtlinie 69/464/EWG des Rates vom 8. Dezem...</td>\n",
       "      <td>Richtlijn 68/464/EEG van de Raad van 8 decem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31969L0063</td>\n",
       "      <td>Council Directive 69/63/EEC of 18 February 1...</td>\n",
       "      <td>DIRECTIVA CONSILIULUI din 18 februarie 1969...</td>\n",
       "      <td>Directiva 69/63/CEE del Consejo, de 18 de fe...</td>\n",
       "      <td>Directive 69/63/CEE du Conseil, du 18 févrie...</td>\n",
       "      <td>Richtlinie 69/63/EWG des Rates vom 18. Febru...</td>\n",
       "      <td>Richtlijn 69/63/EEG van de Raad van 18 febru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       number                                            body_en   \n",
       "0  31969R2264    Regulation (EEC) No 2264/69 of the Commissio...  \\\n",
       "1  31969L0466    Council Directive 69/466/EEC of 8 December 1...   \n",
       "2  31969R2602    Regulation (EEC) No 2602/69 of the Council o...   \n",
       "3  31969L0464    Council Directive 69/464/EEC of 8 December 1...   \n",
       "4  31969L0063    Council Directive 69/63/EEC of 18 February 1...   \n",
       "\n",
       "                                             body_ro   \n",
       "0     REGULAMENTUL COMISIEI (CEE) nr. 2264/69 din...  \\\n",
       "1     DIRECTIVA 69/466/CEE A CONSILIULUI din 8 de...   \n",
       "2     REGULAMENTUL (CEE) nr. 2602/69 AL CONSILIUL...   \n",
       "3     DIRECTIVA 69/464/CEE A CONSILIULUI din 8 de...   \n",
       "4     DIRECTIVA CONSILIULUI din 18 februarie 1969...   \n",
       "\n",
       "                                             body_es   \n",
       "0    Reglamento (CEE) nº 2264/69 de la Comisión, ...  \\\n",
       "1    Directiva 69/466/CEE del Consejo, de 8 de di...   \n",
       "2    Reglamento (CEE) nº 2602/69 del Consejo, de ...   \n",
       "3    Directiva 69/464/CEE del Consejo, de 8 de di...   \n",
       "4    Directiva 69/63/CEE del Consejo, de 18 de fe...   \n",
       "\n",
       "                                             body_fr   \n",
       "0    Règlement (CEE) n° 2264/69 de la Commission,...  \\\n",
       "1    Directive 69/466/CEE du Conseil, du 8 décemb...   \n",
       "2    Règlement (CEE) n° 2602/69 du Conseil, du 18...   \n",
       "3    Directive 69/464/CEE du Conseil, du 8 décemb...   \n",
       "4    Directive 69/63/CEE du Conseil, du 18 févrie...   \n",
       "\n",
       "                                             body_de   \n",
       "0    Verordnung (EWG) Nr. 2264/69 der Kommission ...  \\\n",
       "1    Richtlinie 69/466/EWG des Rates vom 8. Dezem...   \n",
       "2    Verordnung (EWG) Nr. 2602/69 des Rates vom 1...   \n",
       "3    Richtlinie 69/464/EWG des Rates vom 8. Dezem...   \n",
       "4    Richtlinie 69/63/EWG des Rates vom 18. Febru...   \n",
       "\n",
       "                                             body_nl  \n",
       "0    Verordening (EEG) nr. 2264/69 van de Commiss...  \n",
       "1    Richtlijn 69/466/EEG van de Raad van 8 decem...  \n",
       "2    Verordening (EEG) nr. 2602/69 van de Raad va...  \n",
       "3    Richtlijn 68/464/EEG van de Raad van 8 decem...  \n",
       "4    Richtlijn 69/63/EEG van de Raad van 18 febru...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VOaVMESDzdev",
    "outputId": "5549a66e-0bbc-457d-feba-dc463a172139"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was already tokenized - loading data\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "if \"tok_data.pickle\" not in os.listdir(\"Data\"):\n",
    "    preprocessor_en = Preprocessor(language=\"en\")\n",
    "    preprocessor_fr = Preprocessor(language=\"fr\")\n",
    "    preprocessor_other = Preprocessor(language=\"general\")\n",
    "\n",
    "    processed_data = []\n",
    "\n",
    "    for lang in languages:\n",
    "        if lang == \"en\":\n",
    "            preprocessor = preprocessor_en\n",
    "        if lang == \"fr\":\n",
    "            preprocessor = preprocessor_fr\n",
    "        else:\n",
    "            preprocessor = preprocessor_other\n",
    "        aux = [preprocessor.preprocess(doc) for doc in tqdm(df[f\"body_{lang}\"], desc=lang)]\n",
    "        processed_data.append(aux)\n",
    "    \n",
    "    data_dict = {}\n",
    "    for lang, dat in zip(languages, processed_data):\n",
    "      key = f\"body_pre_{lang}\"\n",
    "      data_dict[key] = dat\n",
    "\n",
    "    df_pre = pd.DataFrame(data_dict)\n",
    "    df_pre.to_pickle(\"Data/tok_data.pickle\")\n",
    "else:\n",
    "    print(\"Data was already tokenized - loading data\")\n",
    "    df_pre = pd.read_pickle(\"Data/tok_data.pickle\")\n",
    "    \n",
    "train_df_pre = df_pre[:4000]\n",
    "test_df_pre = df_pre[4000:5000]\n",
    "val_df_pre = df_pre[5000:]\n",
    "\n",
    "# train_df_pre = df_pre[:10]\n",
    "# test_df_pre = df_pre[10:15]\n",
    "# val_df_pre = df_pre[15:20]\n",
    "\n",
    "# dimension = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzplMwlUIkLY",
    "outputId": "814f58f1-829c-4e61-ae14-dc61062b7dbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 6)\n",
      "(1000, 6)\n",
      "(1487, 6)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train_df_pre))\n",
    "print(np.shape(test_df_pre))\n",
    "print(np.shape(val_df_pre))\n",
    "\n",
    "dimensions = [250, 500, 750, 768, 1000, 1250, 1500, 1750, 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fwtPGYwb2yzv",
    "outputId": "8f672336-59d8-4868-a8d2-426caacec89c"
   },
   "outputs": [],
   "source": [
    "# from gensim.test.utils import common_texts\n",
    "# from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "# import time\n",
    "\n",
    "# matrices = dict()\n",
    "# for t in tqdm(languages):\n",
    "#   key = \"body_pre_{}\".format(t)\n",
    "#   #create tagged docs first\n",
    "#   documents = []\n",
    "#   for ind in train_df_pre.index:\n",
    "#     doc = train_df_pre[key][ind]\n",
    "#     tagged_doc = TaggedDocument(doc, [ind])\n",
    "#     documents.append(tagged_doc)\n",
    "\n",
    "#   #Train Doc2Vec Model\n",
    "#   model = Doc2Vec(documents, vector_size=dimension, window=4, min_count=5, workers=120, epochs=100, dm=0)\n",
    "#   training_docs = [model[i] for i in train_df_pre.index]\n",
    "\n",
    "#   ##### ???????????????????????\n",
    "#   # validation_docs = [model[i] for i in val_df.index]\n",
    "#   # test_docs = [model[i] for i in test_df_pre.index]\n",
    "#   ##### ???????????????????????\n",
    "#   #set matrices\n",
    "#   matrices[\"{}_train_vecs\".format(t)] = training_docs\n",
    "#   test = []\n",
    "#   for idx in test_df_pre.index:\n",
    "#     p = model.infer_vector(test_df_pre[key][idx])\n",
    "#     test.append(p)\n",
    "#   matrices[\"{}_test_vecs\".format(t)] = test\n",
    "\n",
    "#   val = []\n",
    "#   for idx in val_df_pre.index:\n",
    "#     p = model.infer_vector(val_df_pre[key][idx])\n",
    "#     val.append(p)\n",
    "#   matrices[\"{}_val_vecs\".format(t)] = val\n",
    "#   # matrices[dimension][\"{}_val_vecs\".format(t)] = np.asarray(validation_docs)\n",
    "#   # matrices[\"{}_test_vecs\".format(t)] = np.asarray(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home2/s4231317/Thesis/Embeddings\n",
      "mkdir: cannot create directory ‘doc2vec’: File exists\n",
      "250 dimension already present\n",
      "500 dimension already present\n",
      "750 dimension already present\n",
      "768 dimension already present\n",
      "1000 dimension already present\n",
      "1250 dimension already present\n",
      "1500 dimension already present\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1750:  17%|█▋        | 1/6 [47:03<3:55:18, 2823.70s/it]"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import time\n",
    "\n",
    "%cd Embeddings\n",
    "!mkdir doc2vec\n",
    "\n",
    "for dimension in dimensions:\n",
    "    matrices = dict()\n",
    "    \n",
    "    if f\"emb_doc2vec_train_{dimension}.pickle\" in os.listdir(\"doc2vec\"):\n",
    "        print(f\"{dimension} dimension already present\")\n",
    "        continue\n",
    "    \n",
    "    for t in tqdm(languages, desc=f\"{dimension}\"):\n",
    "      key = \"body_pre_{}\".format(t)\n",
    "      #create tagged docs first\n",
    "      documents = []\n",
    "      for ind in train_df_pre.index:\n",
    "        doc = train_df_pre[key][ind]\n",
    "        tagged_doc = TaggedDocument(doc, [ind])\n",
    "        documents.append(tagged_doc)\n",
    "\n",
    "      #Train Doc2Vec Model\n",
    "      model = Doc2Vec(documents, vector_size=dimension, window=4, min_count=5, workers=50, epochs=100, dm=0)\n",
    "      training_docs = [model[i] for i in train_df_pre.index]\n",
    "\n",
    "      ##### ???????????????????????\n",
    "      # validation_docs = [model[i] for i in val_df.index]\n",
    "      # test_docs = [model[i] for i in test_df_pre.index]\n",
    "      ##### ???????????????????????\n",
    "      #set matrices\n",
    "      matrices[\"{}_train_vecs\".format(t)] = training_docs\n",
    "      test = []\n",
    "      for idx in test_df_pre.index:\n",
    "        p = model.infer_vector(test_df_pre[key][idx])\n",
    "        test.append(p)\n",
    "      matrices[\"{}_test_vecs\".format(t)] = test\n",
    "\n",
    "      val = []\n",
    "      for idx in val_df_pre.index:\n",
    "        p = model.infer_vector(val_df_pre[key][idx])\n",
    "        val.append(p)\n",
    "      matrices[\"{}_val_vecs\".format(t)] = val\n",
    "      # matrices[dimension][\"{}_val_vecs\".format(t)] = np.asarray(validation_docs)\n",
    "      # matrices[\"{}_test_vecs\".format(t)] = np.asarray(test_docs)\n",
    "    aux_dict = {}\n",
    "    for lang in languages:\n",
    "      aux_dict[f\"{lang}_train_vecs\"] = matrices[f\"{lang}_train_vecs\"]\n",
    "\n",
    "    doc2vec_emb_df_train = pd.DataFrame(aux_dict)\n",
    "    doc2vec_emb_df_train.to_pickle(f\"doc2vec/emb_doc2vec_train_{dimension}.pickle\")\n",
    "\n",
    "    aux_dict = {}\n",
    "    for lang in languages:\n",
    "      aux_dict[f\"{lang}_test_vecs\"] = matrices[f\"{lang}_test_vecs\"]\n",
    "\n",
    "    doc2vec_emb_df_test = pd.DataFrame(aux_dict)\n",
    "    doc2vec_emb_df_test.to_pickle(f\"doc2vec/emb_doc2vec_test_{dimension}.pickle\")\n",
    "\n",
    "    aux_dict = {}\n",
    "    for lang in languages:\n",
    "      aux_dict[f\"{lang}_val_vecs\"] = matrices[f\"{lang}_val_vecs\"]\n",
    "\n",
    "    doc2vec_emb_df_val = pd.DataFrame(aux_dict)\n",
    "    doc2vec_emb_df_val.to_pickle(f\"doc2vec/emb_doc2vec_val_{dimension}.pickle\")\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UNls61eYIwII",
    "outputId": "43b7981e-5de2-4044-df18-0e47c6242a95"
   },
   "outputs": [],
   "source": [
    "len(matrices[\"es_val_vecs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-Ar4BV5aHbwK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home2/s4231317/Thesis/Embeddings\n",
      "mkdir: cannot create directory ‘doc2vec’: File exists\n",
      "/home2/s4231317/Thesis\n"
     ]
    }
   ],
   "source": [
    "%cd Embeddings\n",
    "!mkdir doc2vec\n",
    "\n",
    "aux_dict = {}\n",
    "for lang in languages:\n",
    "  aux_dict[f\"{lang}_train_vecs\"] = matrices[f\"{lang}_train_vecs\"]\n",
    "\n",
    "doc2vec_emb_df_train = pd.DataFrame(aux_dict)\n",
    "doc2vec_emb_df_train.to_pickle(f\"doc2vec/emb_doc2vec_train_{dimension}.pickle\")\n",
    "\n",
    "aux_dict = {}\n",
    "for lang in languages:\n",
    "  aux_dict[f\"{lang}_test_vecs\"] = matrices[f\"{lang}_test_vecs\"]\n",
    "\n",
    "doc2vec_emb_df_test = pd.DataFrame(aux_dict)\n",
    "doc2vec_emb_df_test.to_pickle(f\"doc2vec/emb_doc2vec_test_{dimension}.pickle\")\n",
    "\n",
    "aux_dict = {}\n",
    "for lang in languages:\n",
    "  aux_dict[f\"{lang}_val_vecs\"] = matrices[f\"{lang}_val_vecs\"]\n",
    "\n",
    "doc2vec_emb_df_val = pd.DataFrame(aux_dict)\n",
    "doc2vec_emb_df_val.to_pickle(f\"doc2vec/emb_doc2vec_val_{dimension}.pickle\")\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
